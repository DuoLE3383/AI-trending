# trainer.py (PhiÃªn báº£n nÃ¢ng cáº¥p vá»›i Data Balancing vÃ  Target thá»±c táº¿)
import logging
import sqlite3
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report # Cáº¬P NHáº¬T: ThÃªm thÆ° viá»‡n Ä‘á»ƒ bÃ¡o cÃ¡o chi tiáº¿t
import joblib
from . import config as config

logger = logging.getLogger(__name__)

def train_model() -> float | None:
    """
    Huáº¥n luyá»‡n model dá»±a trÃªn káº¿t quáº£ WIN/LOSS thá»±c táº¿ vÃ  tráº£ vá» Ä‘á»™ chÃ­nh xÃ¡c (accuracy).
    Sá»­ dá»¥ng ká»¹ thuáº­t cÃ¢n báº±ng dá»¯ liá»‡u (undersampling).
    Tráº£ vá» None náº¿u cÃ³ lá»—i hoáº·c khÃ´ng Ä‘á»§ dá»¯ liá»‡u há»£p lá»‡.
    """
    logger.info("ðŸš€ Starting Advanced Model Training...")

    try:
        with sqlite3.connect(config.SQLITE_DB_PATH) as conn:
            # Cáº¢I TIáº¾N: Láº¥y táº¥t cáº£ cÃ¡c giao dá»‹ch Ä‘Ã£ Ä‘Ã³ng (status != 'ACTIVE')
            # vÃ  bao gá»“m cáº£ pnl_percentage Ä‘á»ƒ xÃ¡c Ä‘á»‹nh káº¿t quáº£ má»™t cÃ¡ch chÃ­nh xÃ¡c.
            query = """
            SELECT 
                ema_fast_val, ema_medium_val, ema_slow_val, 
                rsi_val, atr_val, 
                bbands_lower, bbands_middle, bbands_upper, 
                trend,
                status,
                pnl_percentage
            FROM trend_analysis
            WHERE 
                status != 'ACTIVE' 
                AND pnl_percentage IS NOT NULL 
                AND trend IS NOT NULL
            """
            df = pd.read_sql(query, conn)
    except Exception as e:
        logger.error(f"âŒ Failed to load data for training: {e}", exc_info=True)
        return None

    if df.empty:
        logger.warning("âš ï¸ No completed WIN/LOSS trades found to train on. Skipping training.")
        return None

    logger.info(f"Loaded {len(df)} completed trade records from the database.")

    # Cáº¢I TIáº¾N: Táº¡o cá»™t 'outcome' má»™t cÃ¡ch linh hoáº¡t trong Python.
    # Má»™t giao dá»‹ch lÃ  'WIN' náº¿u nÃ³ cháº¡m TP hoáº·c cÃ³ PnL > 0.
    df['outcome'] = df.apply(
        lambda row: 'WIN' if ('TP' in row['status'] or row['pnl_percentage'] > 0) else 'LOSS',
        axis=1
    )

    # Cáº¢I TIáº¾N: Kiá»ƒm tra dá»¯ liá»‡u sau khi táº¡o cá»™t 'outcome'
    outcome_col = 'outcome'
    logger.info(f"Value counts for '{outcome_col}' column:\n" + str(df[outcome_col].value_counts()))
    if df[outcome_col].nunique() < 2:
        logger.error(
            f"Training failed: Only one class ('{df[outcome_col].unique()[0]}') found "
            f"in the outcome column. Cannot train with a single outcome."
        )
        return None
    
    # Cáº¬P NHáº¬T: Danh sÃ¡ch features ban Ä‘áº§u, 'trend' giá» lÃ  má»™t feature
    initial_features = [
        'ema_fast_val', 'ema_medium_val', 'ema_slow_val',
        'rsi_val', 'atr_val',
        'bbands_lower', 'bbands_middle', 'bbands_upper',
        'trend' 
    ]
    target = 'outcome' # Cáº¬P NHáº¬T: Má»¥c tiÃªu dá»± Ä‘oÃ¡n lÃ  'outcome'

    df.dropna(subset=initial_features + [target], inplace=True)

    if len(df) < 50: # Äáº·t má»™t ngÆ°á»¡ng tá»‘i thiá»ƒu cao hÆ¡n cho dá»¯ liá»‡u sáº¡ch
        logger.warning(f"âš ï¸ Not enough clean data. Only {len(df)} rows. Minimum 50 required.")
        return None

    # Cáº¬P NHáº¬T: Logic cÃ¢n báº±ng dá»¯ liá»‡u (Undersampling)
    logger.info("âš–ï¸ Balancing data using Undersampling...")
    df_wins = df[df[target] == 'WIN']
    df_losses = df[df[target] == 'LOSS']

    if df_wins.empty or df_losses.empty:
        logger.warning(f"âš ï¸ Training data needs both WIN and LOSS samples. Skipping.")
        return None

    min_samples = min(len(df_wins), len(df_losses))
    logger.info(f"Balancing to {min_samples} WINs and {min_samples} LOSSes.")
    
    df_balanced = pd.concat([
        df_wins.sample(n=min_samples, random_state=42),
        df_losses.sample(n=min_samples, random_state=42)
    ])

    # Cáº¬P NHáº¬T: Xá»­ lÃ½ feature 'trend' (dáº¡ng text) báº±ng One-Hot Encoding
    X_pre_process = df_balanced[initial_features]
    y = df_balanced[target]
    
    X = pd.get_dummies(X_pre_process, columns=['trend'], drop_first=True)
    
    # LÆ°u láº¡i danh sÃ¡ch features cuá»‘i cÃ¹ng sau khi xá»­ lÃ½
    final_features = X.columns.tolist()

    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    # VÃ¬ Ä‘Ã£ cÃ¢n báº±ng, stratify khÃ´ng cÃ²n quÃ¡ quan trá»ng nhÆ°ng váº«n nÃªn giá»¯
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

    logger.info("ðŸ¤– Fitting RandomForestClassifier model...")
    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')
    model.fit(X_train, y_train)

    # LÆ°u model vÃ  cÃ¡c thÃ nh pháº§n cáº§n thiáº¿t
    joblib.dump(model, "model_trend.pkl")
    joblib.dump(label_encoder, "trend_label_encoder.pkl")
    joblib.dump(final_features, "model_features.pkl") # Cáº¬P NHáº¬T: LÆ°u danh sÃ¡ch feature cuá»‘i cÃ¹ng

    accuracy = model.score(X_test, y_test)
    logger.info(f"âœ… Model trained successfully. Accuracy on test set: {accuracy:.2%}")

    # Cáº¬P NHáº¬T: In bÃ¡o cÃ¡o chi tiáº¿t
    logger.info("ðŸ“Š Classification Report on Test Set:")
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)
    print(report) # In ra console Ä‘á»ƒ xem
    logger.info(f"\n{report}")
    
    return accuracy
