# trainer.py (Phi√™n b·∫£n n√¢ng c·∫•p v·ªõi Data Balancing v√† Target th·ª±c t·∫ø)
import logging
import sqlite3
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report # C·∫¨P NH·∫¨T: Th√™m th∆∞ vi·ªán ƒë·ªÉ b√°o c√°o chi ti·∫øt
import joblib
import config

logger = logging.getLogger(__name__)

def train_model() -> float | None:
    """
    Hu·∫•n luy·ªán model d·ª±a tr√™n k·∫øt qu·∫£ WIN/LOSS th·ª±c t·∫ø v√† tr·∫£ v·ªÅ ƒë·ªô ch√≠nh x√°c (accuracy).
    S·ª≠ d·ª•ng k·ªπ thu·∫≠t c√¢n b·∫±ng d·ªØ li·ªáu (undersampling).
    Tr·∫£ v·ªÅ None n·∫øu c√≥ l·ªói ho·∫∑c kh√¥ng ƒë·ªß d·ªØ li·ªáu h·ª£p l·ªá.
    """
    logger.info("üöÄ Starting Advanced Model Training...")

    try:
        with sqlite3.connect(config.SQLITE_DB_PATH) as conn:
            # C·∫¨P NH·∫¨T: Query ƒë·ªÉ t·∫°o c·ªôt 'outcome' (WIN/LOSS) t·ª´ c·ªôt 'status'
            # v√† ch·ªâ l·∫•y c√°c d√≤ng ƒë√£ c√≥ k·∫øt qu·∫£ r√µ r√†ng.
            query = """
            SELECT 
                ema_fast_val, ema_medium_val, ema_slow_val, 
                rsi_val, atr_val, 
                bbands_lower, bbands_middle, bbands_upper, 
                trend,
                CASE 
                    WHEN status LIKE '%TP%' THEN 'WIN'
                    WHEN status LIKE '%SL%' THEN 'LOSS'
                END as outcome
            FROM trend_analysis
            WHERE status LIKE '%TP%' OR status LIKE '%SL%'
            """
            df = pd.read_sql(query, conn)
    except Exception as e:
        logger.error(f"‚ùå Failed to load data for training: {e}", exc_info=True)
        return None

    if df.empty:
        logger.warning("‚ö†Ô∏è No completed WIN/LOSS trades found. Skipping training.")
        return None

    # C·∫¨P NH·∫¨T: Danh s√°ch features ban ƒë·∫ßu, 'trend' gi·ªù l√† m·ªôt feature
    initial_features = [
        'ema_fast_val', 'ema_medium_val', 'ema_slow_val',
        'rsi_val', 'atr_val',
        'bbands_lower', 'bbands_middle', 'bbands_upper',
        'trend' 
    ]
    target = 'outcome' # C·∫¨P NH·∫¨T: M·ª•c ti√™u d·ª± ƒëo√°n l√† 'outcome'

    df.dropna(subset=initial_features + [target], inplace=True)

    if len(df) < 50: # ƒê·∫∑t m·ªôt ng∆∞·ª°ng t·ªëi thi·ªÉu cao h∆°n cho d·ªØ li·ªáu s·∫°ch
        logger.warning(f"‚ö†Ô∏è Not enough clean data. Only {len(df)} rows. Minimum 50 required.")
        return None

    # C·∫¨P NH·∫¨T: Logic c√¢n b·∫±ng d·ªØ li·ªáu (Undersampling)
    logger.info("‚öñÔ∏è Balancing data using Undersampling...")
    df_wins = df[df[target] == 'WIN']
    df_losses = df[df[target] == 'LOSS']

    if df_wins.empty or df_losses.empty:
        logger.warning(f"‚ö†Ô∏è Training data needs both WIN and LOSS samples. Skipping.")
        return None

    min_samples = min(len(df_wins), len(df_losses))
    logger.info(f"Balancing to {min_samples} WINs and {min_samples} LOSSes.")
    
    df_balanced = pd.concat([
        df_wins.sample(n=min_samples, random_state=42),
        df_losses.sample(n=min_samples, random_state=42)
    ])

    # C·∫¨P NH·∫¨T: X·ª≠ l√Ω feature 'trend' (d·∫°ng text) b·∫±ng One-Hot Encoding
    X_pre_process = df_balanced[initial_features]
    y = df_balanced[target]
    
    X = pd.get_dummies(X_pre_process, columns=['trend'], drop_first=True)
    
    # L∆∞u l·∫°i danh s√°ch features cu·ªëi c√πng sau khi x·ª≠ l√Ω
    final_features = X.columns.tolist()

    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    # V√¨ ƒë√£ c√¢n b·∫±ng, stratify kh√¥ng c√≤n qu√° quan tr·ªçng nh∆∞ng v·∫´n n√™n gi·ªØ
    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

    logger.info("ü§ñ Fitting RandomForestClassifier model...")
    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced')
    model.fit(X_train, y_train)

    # L∆∞u model v√† c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt
    joblib.dump(model, "model_trend.pkl")
    joblib.dump(label_encoder, "trend_label_encoder.pkl")
    joblib.dump(final_features, "model_features.pkl") # C·∫¨P NH·∫¨T: L∆∞u danh s√°ch feature cu·ªëi c√πng

    accuracy = model.score(X_test, y_test)
    logger.info(f"‚úÖ Model trained successfully. Accuracy on test set: {accuracy:.2%}")

    # C·∫¨P NH·∫¨T: In b√°o c√°o chi ti·∫øt
    logger.info("üìä Classification Report on Test Set:")
    y_pred = model.predict(X_test)
    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)
    print(report) # In ra console ƒë·ªÉ xem
    logger.info(f"\n{report}")
    
    return accuracy
